rule calculate_distance_paired_reads_from_refseq_genomes_with_mash:
    conda:
        "../../envs/mash.yml"
    singularity:
        "docker://quay.io/biocontainers/mash:2.2.1--h3d38be6_0" 
    threads:
        8
    input:
        mash_sketch = "references/mash_sketch.msh",
        R1 = "samples/{sample}/reads/raw/{sample}_R1.fastq.gz",
        R2 = "samples/{sample}/reads/raw/{sample}_R2.fastq.gz",
    output:
        distances = "samples/{sample}/contamination/mash/fastq/distances.tsv"
    log:
        logging_folder+"mash/{sample}.log"
    shell:
        """
        cat {input[R1]} {input[R2]} | mash screen -w  {input[mash_sketch]} - > {output[distances]} 2> {log}
        """

rule calculate_distance_assembly_from_refseq_genomes_with_mash:
    threads:
        8
    conda:
        "../../envs/mash.yml"
    singularity:
        "docker://quay.io/biocontainers/mash:2.2.1--h3d38be6_0"
    input:
        mash_sketch = "references/mash_sketch.msh",
        assembly = "samples/{sample}/assembly/spades/contigs_500bp_renamed.fasta",
    output:
        distances = "samples/{sample}/contamination/mash/assembly/distances.tsv"
    log:
        logging_folder+"mash/{sample}.log"
    shell:
        """
        mash screen -w  {input[mash_sketch]} {input[assembly]} > {output[distances]} 2> {log}
        """

rule calculate_distance_single_reads_from_refseq_genomes_with_mash:
    threads:
        8
    conda:
        "../../envs/mash.yml"
    singularity:
        "docker://quay.io/biocontainers/mash:2.2.1--h3d38be6_0"
    input:
        mash_sketch = "references/mash_sketch.msh",
        single = "samples/{sample}/reads/raw/single_{sample}.fastq.gz",
    output:
        distances = "samples/{sample}/contamination/mash/fastq/distances.tsv"
    log:
        logging_folder+"mash/{sample}.log"
    shell:
        """
        cat {input[single]} | mash screen -w {input[mash_sketch]} - > {output[distances]} 2> {log}
        """

rule get_taxonomy_from_mash_results:
    conda:
        "../../envs/entrez-direct.yml"
    input:
        distances = "samples/{sample}/contamination/mash/{fastq_or_assembly}/distances.tsv"
    output:
        taxonomy = "samples/{sample}/contamination/mash/{fastq_or_assembly}/taxonomy.txt"
    shell:
        """
        sort -gr {input[0]}  | cut -f5  | sed "s/\(GCF_[0-9]\+\.[0-9]\+\)_.*/\\1/" | xargs -I % sh -c "esearch -db assembly -query % | efetch -db assembly -format docsum | xtract -pattern DocumentSummary -element SpeciesName" > {output[taxonomy]}
        """


rule format_distances_from_mash_results:
    input:
        distances = "samples/{sample}/contamination/mash/{fastq_or_assembly}/distances.tsv"
    output:
        formated_distances = "samples/{sample}/contamination/mash/{fastq_or_assembly}/distances_formated.tsv",
        formated_distances_no_viruses = "samples/{sample}/contamination/mash/{fastq_or_assembly}/distances_formated_no_virus.tsv"
    shell:
        """
        cat {input[distances]}  | cut -f6 | sed "s/\[\.\.\.]//" | sed "s/\[[0-9]\+ seqs] //" | cut -f2- -d' ' | paste {input[0]} - | cut -f1,2,4,7 | sort -gr  > {output[formated_distances]}
        cat {input[distances]} | cut -f6 | sed "s/\[\.\.\.]//" | sed "s/\[[0-9]\+ seqs] //" | cut -f2- -d' ' | paste {input[0]} - | grep -v "ViralProj" | grep -v "phage" | grep -v "virus" | cut -f1,2,4,7 | sort -gr  > {output[formated_distances_no_viruses]}
        """


rule format_tsv_to_xlsx_mash_results:
    conda:
        "../../envs/python-r.yml"
    singularity:
        "docker://metagenlab/diag-pipeline-python-r:1.1"
    input:
        tsv = "samples/{sample}/contamination/mash/{fastq_or_assembly}/{results}.tsv",
    output:
        xlsx = "samples/{sample}/contamination/mash/{fastq_or_assembly}/{results}.xlsx",
    script:
        "scripts/format_tsv_to_xlsx.py"


rule merge_all_xlsx_mash_results:
    conda:
        "../../envs/python-r.yml"
    singularity:
        "docker://metagenlab/diag-pipeline-python-r:1.1"
    input:
        xlsx = expand("samples/{sample}/contamination/mash/{{fastq_or_assembly}}/{{results}}.xlsx", sample=read_naming.keys())
    output:
        xlsx_out = "report/contamination/mash/{fastq_or_assembly}/{results}.xlsx",
    script:
        "../../rules/annotation/resistance/scripts/merge_non_empty_results.py"


rule paired_reads_classification_with_centrifuge:
    threads:
        4
    conda:
        "../../envs/centrifuge.yml"
    singularity:
        "docker://quay.io/biocontainers/centrifuge:1.0.4_beta--he860b03_3"
    input:
        R1_trimmed = "samples/{sample}/reads/trimmed/R1_paired.fastq",
        R2_trimmed = "samples/{sample}/reads/trimmed/R2_paired.fastq",
        database = "references/centrifuge_db/p_compressed+h+v.1.cf"
    output:
        report = "samples/{sample}/contamination/centrifuge/report.tsv",
        detail = "samples/{sample}/contamination/centrifuge/results.tsv",
    shell:
        """
        a=$(echo {input[2]})
        centrifuge -x ${{a/.1.cf/}} -1 {input[0]} -2 {input[1]} --report-file {output[0]} -S {output[1]}
        """

rule single_reads_classification_with_centrifuge:
    threads:
        4
    conda:
        "../../envs/centrifuge.yml"
    singularity:
        "docker://quay.io/biocontainers/centrifuge:1.0.4_beta--he860b03_3"
    input:
        single = "samples/{sample}/reads/raw/single_{sample}.fastq.gz",
        database = "references/centrifuge_db/p_compressed+h+v.1.cf"
    output:
        report = "samples/{sample}/contamination/centrifuge/report.tsv",
        detail = "samples/{sample}/contamination/centrifuge/results.tsv",
    shell:
        """
        a=$(echo {input[1]})
        centrifuge -x ${{a/.1.cf/}} -U {input[0]} --report-file {output[0]} -S {output[1]}
        """

rule convert_centrifuge_to_kraken_output:
    threads:
        4
    conda:
        "../../envs/centrifuge.yml"
    singularity:
        "docker://quay.io/biocontainers/centrifuge:1.0.4_beta--he860b03_3"
    input:
        detail = "samples/{sample}/contamination/centrifuge/results.tsv",
        database = "references/centrifuge_db/p_compressed+h+v.1.cf"
    output:
        report = "report/contamination/centrifuge/{sample}/centrifuge_kraken_format.txt",
    shell:
        """
        a=$(echo {input[1]})
        centrifuge-kreport -x ${{a/.1.cf/}} {input[0]} | sed -e 's/  \+//g' | sort -nrk3 > {output[0]}
        """

rule format_centrifuge_kraken:
    conda:
        "../../envs/python-r.yml"
    singularity:
        "docker://metagenlab/diag-pipeline-python-r:1.1"
    input:
        report = "report/contamination/centrifuge/{sample}/centrifuge_kraken_format.txt",
    output:
        formatted_out = "report/contamination/centrifuge/{sample}/centrifuge_kraken_format_percent.tsv",
    script:
        "scripts/format_centrifuge_kraken.py"

rule format_centrifuge_output:
    conda:
        "../../envs/python-r.yml"
    singularity:
        "docker://metagenlab/diag-pipeline-python-r:1.1"
    input:
        report = "samples/{sample}/contamination/centrifuge/report.tsv",
        detail = "samples/{sample}/contamination/centrifuge/results.tsv",
    output:
        formatted_out = "report/contamination/centrifuge/{sample}/formatted.tsv",
    script:
        "scripts/format_centrifuge.py"
