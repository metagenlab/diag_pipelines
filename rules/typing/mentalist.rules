
rule determine_mlst_from_trimmed_reads:
    conda:
        "../../envs/mentalist.yml"
    container:
        singularity_envs["mentalist"]
    input:
        fastq1 = "samples/{sample}/reads/trimmed/R1_paired.fastq",
        fastq2 = "samples/{sample}/reads/trimmed/R2_paired.fastq",
    output:
        "samples/{sample}/typing/mentalist.txt",
    params:
        species=lambda wildcards: all_samples.loc[wildcards.sample, "ScientificName"].replace(" ", "_"),
    shell:
        """
        mentalist call -o {output[0]} --db references/mentalist/{params.species}/mlst.db -1 {input.fastq1} -2 {input.fastq2}
        """

rule merge_mentalist_from_all_samples:
    input:
        mlsts = expand("samples/{sample}/typing/mentalist.txt", sample=read_naming.keys())
    params:
        samples=list(read_naming.keys())
    output:
        "report/typing/mlst/mentalist_summary.tsv"
    shell:
        """
        for i in {params.samples}; do
            cat samples/$i/typing/mentalist.txt | sed "s/^R/$i/" >> {output}.tmp
        done
        # remove duplicated header
        awk '!x[$0]++' {output}.tmp > {output}
        rm {output}.tmp
        """
